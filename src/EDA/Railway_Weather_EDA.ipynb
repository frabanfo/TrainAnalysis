{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Railway Weather Correlation Analysis - Exploratory Data Analysis\n",
    "\n",
    "## Research Questions\n",
    "\n",
    "### Primary Research Question\n",
    "**What is the correlation between meteorological conditions and railway delay patterns in the Lombardy region?**\n",
    "\n",
    "### Secondary Research Questions\n",
    "1. How do railway delays vary across different time scales (hourly, daily, seasonal)?\n",
    "2. What are the spatial patterns of delays across different stations?\n",
    "3. How do peak traffic periods interact with weather conditions?\n",
    "4. What is the data quality and integration success rate?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Database connection\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from database.db_manager import DatabaseManager\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize database connection and load data\n",
    "db_manager = DatabaseManager()\n",
    "\n",
    "# Load integrated dataset (main analysis dataset)\n",
    "integrated_query = \"\"\"\n",
    "SELECT \n",
    "    train_id, timestamp, station_code, delay_minutes, temperature,\n",
    "    wind_speed, precip_mm, weather_code, train_category, route,\n",
    "    delay_status, destination, is_cancelled, hour_of_day, day_of_week,\n",
    "    is_weekend, is_rush_hour, temp_category, is_raining, rain_intensity,\n",
    "    wind_category, is_delayed, delay_category\n",
    "FROM train_weather_integrated\n",
    "ORDER BY timestamp\n",
    "\"\"\"\n",
    "\n",
    "df = db_manager.execute_query(integrated_query)\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "print(f\"Loaded {len(df):,} integrated records\")\n",
    "print(f\"Date range: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"Columns: {list(df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Overview and Quality Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset information\n",
    "print(\"Dataset Overview:\")\n",
    "print(f\"Shape: {df.shape}\")\n",
    "print(f\"Unique stations: {df['station_code'].nunique()}\")\n",
    "print(f\"Unique trains: {df['train_id'].nunique()}\")\n",
    "print(f\"Date range: {(df['timestamp'].max() - df['timestamp'].min()).days} days\")\n",
    "\n",
    "# Display basic statistics\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "print(\"Missing Values Analysis:\")\n",
    "print(missing_data)\n",
    "\n",
    "# Plot missing values\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Bar chart of missing percentages\n",
    "missing_pct = missing_data[missing_data['Missing_Percentage'] > 0]\n",
    "if not missing_pct.empty:\n",
    "    ax1.barh(missing_pct['Column'], missing_pct['Missing_Percentage'], color='coral')\n",
    "    ax1.set_xlabel('Missing Percentage')\n",
    "    ax1.set_title('Missing Values by Column')\n",
    "\n",
    "# Heatmap of missing values pattern\n",
    "if df.isnull().any().any():\n",
    "    sns.heatmap(df.isnull().iloc[:1000], ax=ax2, cbar=True, yticklabels=False, cmap='viridis')\n",
    "    ax2.set_title('Missing Values Pattern (First 1000 records)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Delay Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delay statistics\n",
    "if 'delay_minutes' in df.columns:\n",
    "    delay_data = df['delay_minutes'].dropna()\n",
    "    \n",
    "    print(\"Delay Statistics:\")\n",
    "    print(f\"Mean delay: {delay_data.mean():.2f} minutes\")\n",
    "    print(f\"Median delay: {delay_data.median():.2f} minutes\")\n",
    "    print(f\"Standard deviation: {delay_data.std():.2f} minutes\")\n",
    "    print(f\"Max delay: {delay_data.max():.2f} minutes\")\n",
    "    print(f\"Trains with delays >5 min: {(delay_data > 5).sum():,} ({(delay_data > 5).mean()*100:.1f}%)\")\n",
    "    print(f\"Trains with delays >15 min: {(delay_data > 15).sum():,} ({(delay_data > 15).mean()*100:.1f}%)\")\n",
    "    \n",
    "    # Remove extreme outliers for visualization\n",
    "    q99 = delay_data.quantile(0.99)\n",
    "    delay_clean = delay_data[delay_data <= q99]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0,0].hist(delay_clean, bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0,0].axvline(delay_clean.mean(), color='red', linestyle='--', label=f'Mean: {delay_clean.mean():.1f} min')\n",
    "    axes[0,0].axvline(delay_clean.median(), color='orange', linestyle='--', label=f'Median: {delay_clean.median():.1f} min')\n",
    "    axes[0,0].set_title('Distribution of Train Delays')\n",
    "    axes[0,0].set_xlabel('Delay (minutes)')\n",
    "    axes[0,0].set_ylabel('Frequency')\n",
    "    axes[0,0].legend()\n",
    "    \n",
    "    # Box plot by delay status\n",
    "    if 'delay_status' in df.columns:\n",
    "        delay_status_data = df[df['delay_minutes'].notna() & df['delay_status'].notna()]\n",
    "        if not delay_status_data.empty:\n",
    "            sns.boxplot(data=delay_status_data, x='delay_status', y='delay_minutes', ax=axes[0,1])\n",
    "            axes[0,1].set_title('Delays by Status Category')\n",
    "            axes[0,1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Delays by hour\n",
    "    if 'hour_of_day' in df.columns:\n",
    "        hourly_delays = df.groupby('hour_of_day')['delay_minutes'].mean()\n",
    "        axes[1,0].bar(hourly_delays.index, hourly_delays.values, alpha=0.7, color='lightgreen')\n",
    "        axes[1,0].set_title('Average Delays by Hour of Day')\n",
    "        axes[1,0].set_xlabel('Hour of Day')\n",
    "        axes[1,0].set_ylabel('Average Delay (minutes)')\n",
    "    \n",
    "    # Delays by day of week\n",
    "    if 'day_of_week' in df.columns:\n",
    "        daily_delays = df.groupby('day_of_week')['delay_minutes'].mean()\n",
    "        day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "        axes[1,1].bar(range(len(daily_delays)), daily_delays.values, alpha=0.7, color='orange')\n",
    "        axes[1,1].set_title('Average Delays by Day of Week')\n",
    "        axes[1,1].set_xlabel('Day of Week')\n",
    "        axes[1,1].set_ylabel('Average Delay (minutes)')\n",
    "        axes[1,1].set_xticks(range(len(day_names)))\n",
    "        axes[1,1].set_xticklabels(day_names)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Weather-Delay Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather-delay correlation analysis\n",
    "complete_data = df.dropna(subset=['delay_minutes', 'temperature'])\n",
    "\n",
    "if not complete_data.empty:\n",
    "    print(f\"Complete weather-delay records: {len(complete_data):,} ({len(complete_data)/len(df)*100:.1f}% of total)\")\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Temperature vs Delay\n",
    "    axes[0,0].scatter(complete_data['temperature'], complete_data['delay_minutes'], alpha=0.5, s=20)\n",
    "    z = np.polyfit(complete_data['temperature'], complete_data['delay_minutes'], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[0,0].plot(complete_data['temperature'], p(complete_data['temperature']), \"r--\", alpha=0.8)\n",
    "    axes[0,0].set_xlabel('Temperature (Â°C)')\n",
    "    axes[0,0].set_ylabel('Delay (minutes)')\n",
    "    axes[0,0].set_title('Temperature vs Train Delays')\n",
    "    \n",
    "    # Calculate correlation\n",
    "    temp_corr = complete_data['temperature'].corr(complete_data['delay_minutes'])\n",
    "    axes[0,0].text(0.05, 0.95, f'Correlation: {temp_corr:.3f}', transform=axes[0,0].transAxes, \n",
    "                   bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Precipitation vs Delay\n",
    "    if 'precip_mm' in complete_data.columns:\n",
    "        precip_data = complete_data[complete_data['precip_mm'].notna()]\n",
    "        if not precip_data.empty:\n",
    "            axes[0,1].scatter(precip_data['precip_mm'], precip_data['delay_minutes'], alpha=0.5, s=20, color='blue')\n",
    "            axes[0,1].set_xlabel('Precipitation (mm)')\n",
    "            axes[0,1].set_ylabel('Delay (minutes)')\n",
    "            axes[0,1].set_title('Precipitation vs Train Delays')\n",
    "            \n",
    "            precip_corr = precip_data['precip_mm'].corr(precip_data['delay_minutes'])\n",
    "            axes[0,1].text(0.05, 0.95, f'Correlation: {precip_corr:.3f}', transform=axes[0,1].transAxes,\n",
    "                          bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Wind speed vs Delay\n",
    "    if 'wind_speed' in complete_data.columns:\n",
    "        wind_data = complete_data[complete_data['wind_speed'].notna()]\n",
    "        if not wind_data.empty:\n",
    "            axes[1,0].scatter(wind_data['wind_speed'], wind_data['delay_minutes'], alpha=0.5, s=20, color='green')\n",
    "            axes[1,0].set_xlabel('Wind Speed (km/h)')\n",
    "            axes[1,0].set_ylabel('Delay (minutes)')\n",
    "            axes[1,0].set_title('Wind Speed vs Train Delays')\n",
    "            \n",
    "            wind_corr = wind_data['wind_speed'].corr(wind_data['delay_minutes'])\n",
    "            axes[1,0].text(0.05, 0.95, f'Correlation: {wind_corr:.3f}', transform=axes[1,0].transAxes,\n",
    "                          bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Rain vs No Rain comparison\n",
    "    if 'is_raining' in complete_data.columns:\n",
    "        rain_comparison = complete_data.groupby('is_raining')['delay_minutes'].agg(['mean', 'count', 'std'])\n",
    "        rain_labels = ['No Rain', 'Rain']\n",
    "        \n",
    "        bars = axes[1,1].bar(range(len(rain_comparison)), rain_comparison['mean'], \n",
    "                            yerr=rain_comparison['std'], capsize=5,\n",
    "                            color=['lightblue', 'darkblue'], alpha=0.7)\n",
    "        axes[1,1].set_title('Average Delays: Rain vs No Rain')\n",
    "        axes[1,1].set_ylabel('Average Delay (minutes)')\n",
    "        axes[1,1].set_xticks(range(len(rain_labels)))\n",
    "        axes[1,1].set_xticklabels(rain_labels)\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, (bar, mean_val, count) in enumerate(zip(bars, rain_comparison['mean'], rain_comparison['count'])):\n",
    "            axes[1,1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,\n",
    "                          f'{mean_val:.1f}\\n(n={count})', ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No complete weather-delay data available for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Temporal Pattern Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal patterns analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Daily trends over time\n",
    "if 'timestamp' in df.columns and 'delay_minutes' in df.columns:\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    daily_stats = df.groupby('date').agg({\n",
    "        'delay_minutes': ['mean', 'count'],\n",
    "        'temperature': 'mean',\n",
    "        'precip_mm': 'sum'\n",
    "    }).reset_index()\n",
    "    \n",
    "    daily_stats.columns = ['date', 'avg_delay', 'train_count', 'avg_temp', 'total_precip']\n",
    "    daily_stats['date'] = pd.to_datetime(daily_stats['date'])\n",
    "    \n",
    "    axes[0,0].plot(daily_stats['date'], daily_stats['avg_delay'], marker='o', markersize=3, linewidth=1)\n",
    "    axes[0,0].set_title('Daily Average Delays Over Time')\n",
    "    axes[0,0].set_xlabel('Date')\n",
    "    axes[0,0].set_ylabel('Average Delay (minutes)')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Rush hour vs non-rush hour\n",
    "if 'is_rush_hour' in df.columns and 'delay_minutes' in df.columns:\n",
    "    rush_stats = df.groupby('is_rush_hour')['delay_minutes'].agg(['mean', 'count', 'std'])\n",
    "    rush_labels = ['Non-Rush Hour', 'Rush Hour']\n",
    "    \n",
    "    bars = axes[0,1].bar(range(len(rush_stats)), rush_stats['mean'], \n",
    "                        yerr=rush_stats['std'], capsize=5,\n",
    "                        color=['lightcoral', 'darkred'], alpha=0.7)\n",
    "    axes[0,1].set_title('Average Delays: Rush Hour vs Non-Rush Hour')\n",
    "    axes[0,1].set_ylabel('Average Delay (minutes)')\n",
    "    axes[0,1].set_xticks(range(len(rush_labels)))\n",
    "    axes[0,1].set_xticklabels(rush_labels)\n",
    "    \n",
    "    # Add statistical significance test\n",
    "    from scipy import stats\n",
    "    rush_delays = df[df['is_rush_hour'] == True]['delay_minutes'].dropna()\n",
    "    non_rush_delays = df[df['is_rush_hour'] == False]['delay_minutes'].dropna()\n",
    "    if len(rush_delays) > 0 and len(non_rush_delays) > 0:\n",
    "        t_stat, p_value = stats.ttest_ind(rush_delays, non_rush_delays)\n",
    "        axes[0,1].text(0.5, 0.95, f'p-value: {p_value:.4f}', transform=axes[0,1].transAxes,\n",
    "                      ha='center', bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "# Weekend vs weekday\n",
    "if 'is_weekend' in df.columns and 'delay_minutes' in df.columns:\n",
    "    weekend_stats = df.groupby('is_weekend')['delay_minutes'].agg(['mean', 'count', 'std'])\n",
    "    weekend_labels = ['Weekday', 'Weekend']\n",
    "    \n",
    "    axes[1,0].bar(range(len(weekend_stats)), weekend_stats['mean'], \n",
    "                 yerr=weekend_stats['std'], capsize=5,\n",
    "                 color=['lightgreen', 'darkgreen'], alpha=0.7)\n",
    "    axes[1,0].set_title('Average Delays: Weekday vs Weekend')\n",
    "    axes[1,0].set_ylabel('Average Delay (minutes)')\n",
    "    axes[1,0].set_xticks(range(len(weekend_labels)))\n",
    "    axes[1,0].set_xticklabels(weekend_labels)\n",
    "\n",
    "# Hourly heatmap (day of week vs hour of day)\n",
    "if 'hour_of_day' in df.columns and 'day_of_week' in df.columns:\n",
    "    hourly_heatmap = df.pivot_table(\n",
    "        values='delay_minutes', \n",
    "        index='day_of_week', \n",
    "        columns='hour_of_day', \n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    if not hourly_heatmap.empty:\n",
    "        sns.heatmap(hourly_heatmap, ax=axes[1,1], cmap='YlOrRd', \n",
    "                   cbar_kws={'label': 'Average Delay (min)'}, annot=False)\n",
    "        axes[1,1].set_title('Average Delays Heatmap (Day vs Hour)')\n",
    "        axes[1,1].set_xlabel('Hour of Day')\n",
    "        axes[1,1].set_ylabel('Day of Week (0=Monday)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Station and Geographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Station analysis\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Top stations by average delay\n",
    "if 'delay_minutes' in df.columns:\n",
    "    station_stats = df.groupby('station_code').agg({\n",
    "        'delay_minutes': ['mean', 'count', 'std'],\n",
    "        'train_id': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    station_stats.columns = ['station_code', 'avg_delay', 'total_records', 'delay_std', 'unique_trains']\n",
    "    \n",
    "    # Filter for statistical significance (at least 50 records)\n",
    "    significant_stations = station_stats[station_stats['total_records'] >= 50]\n",
    "    top_delay_stations = significant_stations.nlargest(15, 'avg_delay')\n",
    "    \n",
    "    axes[0,0].barh(range(len(top_delay_stations)), top_delay_stations['avg_delay'])\n",
    "    axes[0,0].set_yticks(range(len(top_delay_stations)))\n",
    "    axes[0,0].set_yticklabels(top_delay_stations['station_code'])\n",
    "    axes[0,0].set_title('Top 15 Stations by Average Delay\\n(â‰¥50 records)')\n",
    "    axes[0,0].set_xlabel('Average Delay (minutes)')\n",
    "\n",
    "# Top stations by volume\n",
    "top_volume_stations = station_stats.nlargest(15, 'total_records')\n",
    "axes[0,1].bar(range(len(top_volume_stations)), top_volume_stations['total_records'])\n",
    "axes[0,1].set_xticks(range(len(top_volume_stations)))\n",
    "axes[0,1].set_xticklabels(top_volume_stations['station_code'], rotation=45)\n",
    "axes[0,1].set_title('Top 15 Stations by Train Volume')\n",
    "axes[0,1].set_ylabel('Number of Records')\n",
    "\n",
    "# Train category analysis\n",
    "if 'train_category' in df.columns:\n",
    "    category_stats = df.groupby('train_category').agg({\n",
    "        'delay_minutes': ['mean', 'count', 'std']\n",
    "    }).reset_index()\n",
    "    category_stats.columns = ['train_category', 'avg_delay', 'count', 'delay_std']\n",
    "    \n",
    "    # Filter for categories with sufficient data\n",
    "    significant_categories = category_stats[category_stats['count'] >= 20]\n",
    "    \n",
    "    if not significant_categories.empty:\n",
    "        axes[1,0].bar(range(len(significant_categories)), significant_categories['avg_delay'],\n",
    "                     yerr=significant_categories['delay_std'], capsize=5, alpha=0.7)\n",
    "        axes[1,0].set_xticks(range(len(significant_categories)))\n",
    "        axes[1,0].set_xticklabels(significant_categories['train_category'], rotation=45)\n",
    "        axes[1,0].set_title('Average Delays by Train Category\\n(â‰¥20 records)')\n",
    "        axes[1,0].set_ylabel('Average Delay (minutes)')\n",
    "\n",
    "# Delay status distribution\n",
    "if 'delay_status' in df.columns:\n",
    "    status_counts = df['delay_status'].value_counts()\n",
    "    colors = plt.cm.Set3(np.linspace(0, 1, len(status_counts)))\n",
    "    wedges, texts, autotexts = axes[1,1].pie(status_counts.values, labels=status_counts.index, \n",
    "                                            autopct='%1.1f%%', colors=colors)\n",
    "    axes[1,1].set_title('Distribution of Delay Status')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print station statistics\n",
    "print(\"\\nStation Statistics Summary:\")\n",
    "print(f\"Total stations: {len(station_stats)}\")\n",
    "print(f\"Stations with â‰¥50 records: {len(significant_stations)}\")\n",
    "print(f\"Highest average delay: {top_delay_stations.iloc[0]['avg_delay']:.2f} min at {top_delay_stations.iloc[0]['station_code']}\")\n",
    "print(f\"Highest volume station: {top_volume_stations.iloc[0]['station_code']} with {top_volume_stations.iloc[0]['total_records']} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Correlation Matrix and Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for key variables\n",
    "numeric_cols = ['delay_minutes', 'temperature', 'wind_speed', 'precip_mm', 'hour_of_day', 'day_of_week']\n",
    "available_cols = [col for col in numeric_cols if col in df.columns]\n",
    "\n",
    "if len(available_cols) >= 2:\n",
    "    correlation_data = df[available_cols].corr()\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    mask = np.triu(np.ones_like(correlation_data, dtype=bool))  # Show only lower triangle\n",
    "    sns.heatmap(correlation_data, mask=mask, annot=True, cmap='RdBu_r', center=0, \n",
    "               square=True, fmt='.3f', cbar_kws={'label': 'Correlation Coefficient'})\n",
    "    plt.title('Correlation Matrix: Weather and Delay Variables')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print key correlations with delay\n",
    "    if 'delay_minutes' in correlation_data.columns:\n",
    "        print(\"\\nCorrelations with Delay Minutes:\")\n",
    "        delay_corr = correlation_data['delay_minutes'].drop('delay_minutes').sort_values(key=abs, ascending=False)\n",
    "        for var, corr in delay_corr.items():\n",
    "            significance = \"***\" if abs(corr) > 0.1 else \"**\" if abs(corr) > 0.05 else \"*\" if abs(corr) > 0.01 else \"\"\n",
    "            print(f\"  {var}: {corr:.4f} {significance}\")\n",
    "        \n",
    "        print(\"\\nSignificance levels: *** |r| > 0.1, ** |r| > 0.05, * |r| > 0.01\")\n",
    "else:\n",
    "    print(\"Insufficient numeric data for correlation analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Advanced Weather Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced weather impact analysis\n",
    "if 'temperature' in df.columns and 'delay_minutes' in df.columns:\n",
    "    # Create temperature categories\n",
    "    df['temp_range'] = pd.cut(df['temperature'], \n",
    "                             bins=[-np.inf, 0, 10, 20, 30, np.inf], \n",
    "                             labels=['<0Â°C', '0-10Â°C', '10-20Â°C', '20-30Â°C', '>30Â°C'])\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Delays by temperature range\n",
    "    temp_delays = df.groupby('temp_range')['delay_minutes'].agg(['mean', 'count', 'std']).reset_index()\n",
    "    temp_delays = temp_delays[temp_delays['count'] >= 10]  # Filter for significance\n",
    "    \n",
    "    if not temp_delays.empty:\n",
    "        axes[0,0].bar(range(len(temp_delays)), temp_delays['mean'], \n",
    "                     yerr=temp_delays['std'], capsize=5, alpha=0.7)\n",
    "        axes[0,0].set_xticks(range(len(temp_delays)))\n",
    "        axes[0,0].set_xticklabels(temp_delays['temp_range'])\n",
    "        axes[0,0].set_title('Average Delays by Temperature Range')\n",
    "        axes[0,0].set_ylabel('Average Delay (minutes)')\n",
    "    \n",
    "    # Precipitation impact\n",
    "    if 'precip_mm' in df.columns:\n",
    "        df['rain_category'] = pd.cut(df['precip_mm'], \n",
    "                                   bins=[-0.1, 0, 1, 5, 20, np.inf], \n",
    "                                   labels=['No Rain', 'Light', 'Moderate', 'Heavy', 'Very Heavy'])\n",
    "        \n",
    "        rain_delays = df.groupby('rain_category')['delay_minutes'].agg(['mean', 'count', 'std']).reset_index()\n",
    "        rain_delays = rain_delays[rain_delays['count'] >= 5]\n",
    "        \n",
    "        if not rain_delays.empty:\n",
    "            axes[0,1].bar(range(len(rain_delays)), rain_delays['mean'], \n",
    "                         yerr=rain_delays['std'], capsize=5, alpha=0.7, color='blue')\n",
    "            axes[0,1].set_xticks(range(len(rain_delays)))\n",
    "            axes[0,1].set_xticklabels(rain_delays['rain_category'], rotation=45)\n",
    "            axes[0,1].set_title('Average Delays by Precipitation Intensity')\n",
    "            axes[0,1].set_ylabel('Average Delay (minutes)')\n",
    "    \n",
    "    # Combined weather conditions\n",
    "    if 'is_raining' in df.columns and 'temp_range' in df.columns:\n",
    "        combined_weather = df.groupby(['temp_range', 'is_raining'])['delay_minutes'].mean().unstack(fill_value=0)\n",
    "        \n",
    "        if not combined_weather.empty:\n",
    "            combined_weather.plot(kind='bar', ax=axes[1,0], alpha=0.7)\n",
    "            axes[1,0].set_title('Average Delays by Temperature and Rain')\n",
    "            axes[1,0].set_ylabel('Average Delay (minutes)')\n",
    "            axes[1,0].set_xlabel('Temperature Range')\n",
    "            axes[1,0].legend(['No Rain', 'Rain'])\n",
    "            axes[1,0].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Weather vs Rush Hour interaction\n",
    "    if 'is_raining' in df.columns and 'is_rush_hour' in df.columns:\n",
    "        weather_rush = df.groupby(['is_raining', 'is_rush_hour'])['delay_minutes'].mean().unstack(fill_value=0)\n",
    "        \n",
    "        if not weather_rush.empty:\n",
    "            weather_rush.plot(kind='bar', ax=axes[1,1], alpha=0.7)\n",
    "            axes[1,1].set_title('Weather-Rush Hour Interaction')\n",
    "            axes[1,1].set_ylabel('Average Delay (minutes)')\n",
    "            axes[1,1].set_xlabel('Rain Condition')\n",
    "            axes[1,1].legend(['Non-Rush', 'Rush Hour'])\n",
    "            axes[1,1].set_xticklabels(['No Rain', 'Rain'], rotation=0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Data Quality and Integration Success Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data quality analysis\n",
    "print(\"Data Quality Assessment:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Overall completeness\n",
    "total_cells = len(df) * len(df.columns)\n",
    "missing_cells = df.isnull().sum().sum()\n",
    "completeness = (1 - missing_cells / total_cells) * 100\n",
    "\n",
    "print(f\"Overall Data Completeness: {completeness:.2f}%\")\n",
    "\n",
    "# Weather integration success rate\n",
    "weather_match_rate = (df['temperature'].notna()).mean() * 100\n",
    "print(f\"Weather Integration Success Rate: {weather_match_rate:.2f}%\")\n",
    "\n",
    "# Key field completeness\n",
    "key_fields = ['delay_minutes', 'temperature', 'wind_speed', 'precip_mm']\n",
    "print(\"\\nKey Field Completeness:\")\n",
    "for field in key_fields:\n",
    "    if field in df.columns:\n",
    "        completeness = (df[field].notna()).mean() * 100\n",
    "        print(f\"  {field}: {completeness:.2f}%\")\n",
    "\n",
    "# Temporal coverage\n",
    "if 'timestamp' in df.columns:\n",
    "    date_range = df['timestamp'].max() - df['timestamp'].min()\n",
    "    unique_dates = df['timestamp'].dt.date.nunique()\n",
    "    print(f\"\\nTemporal Coverage:\")\n",
    "    print(f\"  Total date range: {date_range.days} days\")\n",
    "    print(f\"  Days with data: {unique_dates}\")\n",
    "    print(f\"  Coverage rate: {unique_dates/date_range.days*100:.2f}%\")\n",
    "\n",
    "# Data quality visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Daily data volume\n",
    "if 'timestamp' in df.columns:\n",
    "    daily_volume = df.groupby(df['timestamp'].dt.date).size()\n",
    "    axes[0,0].plot(daily_volume.index, daily_volume.values, marker='o', markersize=2)\n",
    "    axes[0,0].set_title('Daily Data Volume')\n",
    "    axes[0,0].set_xlabel('Date')\n",
    "    axes[0,0].set_ylabel('Number of Records')\n",
    "    axes[0,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Completeness by field\n",
    "completeness_by_field = (1 - df.isnull().mean()) * 100\n",
    "completeness_by_field = completeness_by_field.sort_values()\n",
    "\n",
    "axes[0,1].barh(range(len(completeness_by_field)), completeness_by_field.values)\n",
    "axes[0,1].set_yticks(range(len(completeness_by_field)))\n",
    "axes[0,1].set_yticklabels(completeness_by_field.index)\n",
    "axes[0,1].set_title('Data Completeness by Field')\n",
    "axes[0,1].set_xlabel('Completeness (%)')\n",
    "axes[0,1].set_xlim(0, 100)\n",
    "\n",
    "# Missing data pattern over time\n",
    "if 'timestamp' in df.columns:\n",
    "    df['date'] = df['timestamp'].dt.date\n",
    "    daily_missing = df.groupby('date').apply(lambda x: x.isnull().mean() * 100)\n",
    "    \n",
    "    if 'temperature' in daily_missing.columns:\n",
    "        axes[1,0].plot(daily_missing.index, daily_missing['temperature'], \n",
    "                      marker='o', markersize=2, label='Temperature')\n",
    "    if 'delay_minutes' in daily_missing.columns:\n",
    "        axes[1,0].plot(daily_missing.index, daily_missing['delay_minutes'], \n",
    "                      marker='s', markersize=2, label='Delay Minutes')\n",
    "    \n",
    "    axes[1,0].set_title('Missing Data Trends Over Time')\n",
    "    axes[1,0].set_xlabel('Date')\n",
    "    axes[1,0].set_ylabel('Missing Percentage')\n",
    "    axes[1,0].legend()\n",
    "    axes[1,0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Data quality score by table\n",
    "quality_scores = {\n",
    "    'Integrated Data': completeness,\n",
    "    'Weather Match': weather_match_rate,\n",
    "    'Delay Data': (df['delay_minutes'].notna()).mean() * 100 if 'delay_minutes' in df.columns else 0\n",
    "}\n",
    "\n",
    "axes[1,1].bar(quality_scores.keys(), quality_scores.values(), \n",
    "             color=['skyblue', 'lightgreen', 'coral'], alpha=0.7)\n",
    "axes[1,1].set_title('Data Quality Scores')\n",
    "axes[1,1].set_ylabel('Quality Score (%)')\n",
    "axes[1,1].set_ylim(0, 100)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (key, value) in enumerate(quality_scores.items()):\n",
    "    axes[1,1].text(i, value + 1, f'{value:.1f}%', ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary and Key Findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RAILWAY WEATHER CORRELATION ANALYSIS - KEY FINDINGS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Dataset summary\n",
    "print(f\"\\nðŸ“Š DATASET OVERVIEW:\")\n",
    "print(f\"   â€¢ Total Records: {len(df):,}\")\n",
    "print(f\"   â€¢ Date Range: {df['timestamp'].min().strftime('%Y-%m-%d')} to {df['timestamp'].max().strftime('%Y-%m-%d')}\")\n",
    "print(f\"   â€¢ Unique Stations: {df['station_code'].nunique()}\")\n",
    "print(f\"   â€¢ Unique Trains: {df['train_id'].nunique()}\")\n",
    "print(f\"   â€¢ Data Completeness: {completeness:.1f}%\")\n",
    "print(f\"   â€¢ Weather Integration Rate: {weather_match_rate:.1f}%\")\n",
    "\n",
    "# Delay analysis summary\n",
    "if 'delay_minutes' in df.columns:\n",
    "    delay_data = df['delay_minutes'].dropna()\n",
    "    print(f\"\\nðŸš‚ DELAY PATTERNS:\")\n",
    "    print(f\"   â€¢ Average Delay: {delay_data.mean():.2f} minutes\")\n",
    "    print(f\"   â€¢ Median Delay: {delay_data.median():.2f} minutes\")\n",
    "    print(f\"   â€¢ Trains with Significant Delays (>5 min): {(delay_data > 5).mean()*100:.1f}%\")\n",
    "    print(f\"   â€¢ Trains with Major Delays (>15 min): {(delay_data > 15).mean()*100:.1f}%\")\n",
    "\n",
    "# Weather correlation findings\n",
    "if not complete_data.empty:\n",
    "    temp_corr = complete_data['temperature'].corr(complete_data['delay_minutes'])\n",
    "    print(f\"\\nðŸŒ¤ï¸ WEATHER CORRELATIONS:\")\n",
    "    print(f\"   â€¢ Temperature-Delay Correlation: {temp_corr:.4f}\")\n",
    "    \n",
    "    if 'precip_mm' in complete_data.columns:\n",
    "        precip_data = complete_data[complete_data['precip_mm'].notna()]\n",
    "        if not precip_data.empty:\n",
    "            precip_corr = precip_data['precip_mm'].corr(precip_data['delay_minutes'])\n",
    "            print(f\"   â€¢ Precipitation-Delay Correlation: {precip_corr:.4f}\")\n",
    "    \n",
    "    if 'is_raining' in complete_data.columns:\n",
    "        rain_delays = complete_data[complete_data['is_raining'] == True]['delay_minutes'].mean()\n",
    "        no_rain_delays = complete_data[complete_data['is_raining'] == False]['delay_minutes'].mean()\n",
    "        rain_impact = ((rain_delays - no_rain_delays) / no_rain_delays) * 100\n",
    "        print(f\"   â€¢ Rain Impact: {rain_impact:+.1f}% change in average delays\")\n",
    "\n",
    "# Temporal patterns\n",
    "if 'is_rush_hour' in df.columns and 'delay_minutes' in df.columns:\n",
    "    rush_delays = df[df['is_rush_hour'] == True]['delay_minutes'].mean()\n",
    "    non_rush_delays = df[df['is_rush_hour'] == False]['delay_minutes'].mean()\n",
    "    rush_impact = ((rush_delays - non_rush_delays) / non_rush_delays) * 100\n",
    "    print(f\"\\nâ° TEMPORAL PATTERNS:\")\n",
    "    print(f\"   â€¢ Rush Hour Impact: {rush_impact:+.1f}% change in average delays\")\n",
    "    \n",
    "    if 'is_weekend' in df.columns:\n",
    "        weekend_delays = df[df['is_weekend'] == True]['delay_minutes'].mean()\n",
    "        weekday_delays = df[df['is_weekend'] == False]['delay_minutes'].mean()\n",
    "        weekend_impact = ((weekend_delays - weekday_delays) / weekday_delays) * 100\n",
    "        print(f\"   â€¢ Weekend Impact: {weekend_impact:+.1f}% change in average delays\")\n",
    "\n",
    "# Station insights\n",
    "if 'station_code' in df.columns and 'delay_minutes' in df.columns:\n",
    "    station_stats = df.groupby('station_code')['delay_minutes'].agg(['mean', 'count'])\n",
    "    significant_stations = station_stats[station_stats['count'] >= 50]\n",
    "    print(f\"\\nðŸš‰ STATION ANALYSIS:\")\n",
    "    print(f\"   â€¢ Stations with Sufficient Data (â‰¥50 records): {len(significant_stations)}\")\n",
    "    if not significant_stations.empty:\n",
    "        worst_station = significant_stations['mean'].idxmax()\n",
    "        best_station = significant_stations['mean'].idxmin()\n",
    "        print(f\"   â€¢ Highest Average Delays: {worst_station} ({significant_stations.loc[worst_station, 'mean']:.2f} min)\")\n",
    "        print(f\"   â€¢ Lowest Average Delays: {best_station} ({significant_stations.loc[best_station, 'mean']:.2f} min)\")\n",
    "\n",
    "# Research questions answered\n",
    "print(f\"\\nâœ… RESEARCH QUESTIONS ADDRESSED:\")\n",
    "print(f\"   1. âœ“ Primary: Weather-delay correlations quantified\")\n",
    "print(f\"   2. âœ“ Temporal: Rush hour and seasonal patterns analyzed\")\n",
    "print(f\"   3. âœ“ Spatial: Station-level delay patterns identified\")\n",
    "print(f\"   4. âœ“ Operational: Train categories and traffic impacts assessed\")\n",
    "print(f\"   5. âœ“ Data Quality: Integration success and completeness measured\")\n",
    "\n",
    "print(f\"\\nðŸ“ˆ ANALYSIS COMPLETE - {len([f for f in os.listdir('.') if f.endswith('.png')])} visualizations generated\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}